{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os;\n",
    "import re;\n",
    "import copy;\n",
    "import numpy as np;\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1\"#选择哪一块gpu,-1代表cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file <'NO'> was ignored for <txt> file only\n",
      "file <'Nothing.txt'> was ignored for its zero size\n",
      "done, while Getting 8 documents loaded\n"
     ]
    }
   ],
   "source": [
    "# 载入文档\n",
    "def load_documents(path):\n",
    "    files =[];\n",
    "    for filename in os.listdir(path):\n",
    "        path_of_file = path + '/' + filename;\n",
    "        if os.path.getsize(path_of_file) > 0:\n",
    "            if len(filename) > 3 and filename[-3:] == 'txt':\n",
    "                f = open(path_of_file,'r');\n",
    "                content = f.read();\n",
    "                files.append(content);\n",
    "                f.close();\n",
    "            else:\n",
    "                print('file <\\'' + filename + '\\'> was ignored for <txt> file only');\n",
    "        else:\n",
    "            print('file <\\'' + filename + '\\'> was ignored for its zero size');\n",
    "    print('done, while Getting {} documents loaded'.format(len(files)))\n",
    "    return files;\n",
    "# 文档目录，注意修改。\n",
    "path = '/home/pp21/data/document';\n",
    "document = load_documents(path);\n",
    "# '''2个名为 <No*> 的文件为验证上述函数泛化能力的空文件'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 载入停顿词\n",
    "path = '/home/pp21/data/stop_words/stop words.txt';\n",
    "f = open(path,'r',);\n",
    "stop_words = f.read();\n",
    "f.close();\n",
    "stop_words = stop_words.split('\\n');\n",
    "# 载入实体\n",
    "stop_words += ['The','sam','michelle','lele'];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(document,clear_list,rm_words=[],reverse=True):\n",
    "    # 将文档合并为一个词序列\n",
    "    words_sequence = [];\n",
    "    words_sequence_doc = [];\n",
    "    for text in document:\n",
    "        text = re.sub(clear_list,' ',text);# 替换指定符号为空格\n",
    "        text = re.sub(\"( )+\",\" \",text); # 将连续多个空格替换成一个\n",
    "        words_list = text.split(' ');\n",
    "        words_sequence += words_list;\n",
    "        words_sequence_doc.append(words_list);\n",
    "    # 去掉不需要的单词\n",
    "    selected_sequency = [];\n",
    "    for w in words_sequence:\n",
    "        if not ((w == '') or (w in rm_words)):\n",
    "            selected_sequency.append(w);\n",
    "    selected_sequency_doc = [];\n",
    "    for text in words_sequence_doc:\n",
    "        tmp = [];\n",
    "        for w in text:\n",
    "            if not ((w == '') or (w in rm_words)):\n",
    "                tmp.append(w);\n",
    "        selected_sequency_doc.append(tmp);\n",
    "    # 从词序列中统计词频\n",
    "    N = len(selected_sequency);\n",
    "    voc = {};   # 单词表\n",
    "    for word in selected_sequency:\n",
    "        if not word in voc.keys():\n",
    "            voc.update({word:1});\n",
    "        else:\n",
    "            voc[word]+=1\n",
    "    # 将单词按词频排序\n",
    "    words = list(voc.keys());\n",
    "    frequency = list(voc.values());\n",
    "    # 按照frequency排序，获得排序后frequency和原下标\n",
    "    sorted_nums = sorted(enumerate(frequency), key=lambda x: x[1]);\n",
    "    idx = [j[0] for j in sorted_nums];\n",
    "    nums = [j[1] for j in sorted_nums];\n",
    "    # 按照下标解出对应单词\n",
    "    sorted_words = [];\n",
    "    for i in idx:\n",
    "        sorted_words.append(words[i]);\n",
    "    if reverse == True:\n",
    "        sorted_words.reverse();\n",
    "        nums.reverse();\n",
    "    sorted_voc = dict(zip(sorted_words,nums));\n",
    "    return sorted_voc,selected_sequency,selected_sequency_doc;\n",
    "clear_list = '[(),.”“\\\":;\\n!?]'# 指定需要替换的符号\n",
    "voc,words_sequency,words_sequency_doc = tokenize(document,clear_list,rm_words=stop_words);\n",
    "voc_list = list(voc.keys());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将单词转化为编号\n",
    "def words2idx(words_sequency_doc,voc_list):\n",
    "    w2i = {voc_list[i]:i for i in range(len(voc_list))};\n",
    "    idx = [];\n",
    "    for text in words_sequency_doc:\n",
    "        for w in text:\n",
    "            tmp = [];\n",
    "            if w in voc_list:\n",
    "                index = w2i[w];\n",
    "                tmp.append(index);\n",
    "        idx.append(tmp);\n",
    "    return idx;\n",
    "idx = words2idx(words_sequency_doc,voc_list);# 两者结果相同\n",
    "# idx_list_resw = words2idx(words_list_rmsw,words); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超参数\n",
    "K = 4;\n",
    "alpha = [1/K]*K;# K，p(zk|dm) 所服从分布 Dir(alpha) 的超参数\n",
    "beta = [1/len(voc_list)]*len(voc_list);# V，p(wj|zk) 所服从分布 Dir(beta) 的超参数\n",
    "# 参数\n",
    "V = len(voc_list);# 词典内容数量\n",
    "M = len(document);# 文档数\n",
    "N = np.zeros(M,dtype=np.int32);# 各文档词数\n",
    "for i in range(len(idx)):\n",
    "    N[i] = len(idx[i]);\n",
    "num_words_document = np.sum(N);\n",
    "# 分布参数\n",
    "p = np.zeros(K); # K采样时所需要的分布\n",
    "theta = np.zeros((M,K));# 文档-主题分布\n",
    "phi = np.zeros((K,V));# 主题-词项分布\n",
    "# 主题参数\n",
    "z = [];# 单词的主题 M*N_m\n",
    "# initiate\n",
    "for i in range(len(idx)):\n",
    "    z.append(np.zeros(len(idx[i]),dtype=np.int32));\n",
    "# 计数参数\n",
    "nw = np.zeros((V,K)); # V*K，词j与主题k上的共现频数\n",
    "nd = np.zeros((M,K));# M*K，文章i属于主题k的词的频数\n",
    "nw_s = np.zeros(K); # K， 属于主题k的词的频数\n",
    "nd_s = np.zeros(M); # M，文章i的词频\n",
    "for i in range(M):\n",
    "    nd_s[i] = N[i];\n",
    "    for j in range(N[i]):\n",
    "        topic_index = np.random.randint(0,K);\n",
    "        words_index = idx[i][j];\n",
    "        z[i][j] = topic_index;\n",
    "        nw[words_index][topic_index] += 1;\n",
    "        nd[i][topic_index] += 1;\n",
    "        nw_s[topic_index] += 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/10, delta: theta:0.5000, phi:0.5005\n",
      "epoch 2/10, delta: theta:0.5000, phi:0.4986\n",
      "epoch 3/10, delta: theta:0.5000, phi:0.3336\n",
      "epoch 4/10, delta: theta:0.5000, phi:0.5005\n",
      "epoch 5/10, delta: theta:0.5000, phi:0.5007\n",
      "epoch 6/10, delta: theta:0.5000, phi:0.5005\n",
      "epoch 7/10, delta: theta:0.5000, phi:0.5005\n",
      "epoch 8/10, delta: theta:0.5000, phi:0.5000\n",
      "epoch 9/10, delta: theta:0.5000, phi:0.5005\n",
      "epoch 10/10, delta: theta:0.5000, phi:0.5005\n"
     ]
    }
   ],
   "source": [
    "epoch_n = 10;\n",
    "for e in range(epoch_n):\n",
    "    last_theta = copy.deepcopy(theta);\n",
    "    last_phi = copy.deepcopy(phi);\n",
    "    for i in range(M):# 遍历文档\n",
    "        for j in range(N[i]):# 遍历该文档单词\n",
    "            # 单个单词迭代\n",
    "            topic_index = z[i][j];# 提取该单词的主题\n",
    "            words_index = idx[i][j];# 单词下标\n",
    "            # 获取排除该单词的分布\n",
    "            nw[words_index,topic_index] -= 1;\n",
    "            nw_s[topic_index] -= 1;\n",
    "            nd[i,topic_index] -= 1;\n",
    "            nd_s[i] -= 1;\n",
    "            # 采样\n",
    "            # 初始化该单词所属主题的分布\n",
    "            for k in range(K):\n",
    "                p[k] = ((nw[words_index][k]+beta[words_index])/(nw_s[k] + np.sum(beta))) * (nd[i][k]+alpha[k]);\n",
    "            # 堵轮盘算法采样\n",
    "            u = np.random.uniform(0,np.sum(p));\n",
    "            for topic_index in range(K):\n",
    "                if p[:topic_index+1].sum() >= u:\n",
    "                    break;\n",
    "            # print(topic_index,end=' ')\n",
    "            nw[words_index,topic_index] += 1;\n",
    "            nw_s[topic_index] += 1;\n",
    "            nd[i,topic_index] += 1;\n",
    "            nd_s[i] += 1;\n",
    "            z[i][j] = topic_index;# 重置单词的主题\n",
    "    # 计数phi和theta\n",
    "    for i in range(M):\n",
    "        for k in range(K):\n",
    "            theta[i,k] = (nd[i,k]+alpha[k])/(nd_s[i]+np.sum(alpha));\n",
    "    for k in range(K):\n",
    "        for j in range(V):\n",
    "            phi[k,j] = (nw[j,k]+beta[j])/(nw_s[k]+np.sum(beta));\n",
    "    delta = [\n",
    "        np.max(np.abs(last_theta - theta)),\n",
    "        np.max(np.abs(last_phi - phi))\n",
    "    ];\n",
    "    print('epoch {}/{}, delta: theta:{:.4f}, phi:{:.4f}'.format(e+1,epoch_n,delta[0],delta[1]),end='\\n');\n",
    "    # print(\" p[-1]:{:.2f}\".format(p[-1]),end='\\n');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic of documents:\n",
      "Document\\topic\t 1 \t 2 \t 3 \t 4 \t\n",
      "                --------------------------------\n",
      "\t1    |\t 0.1250\t 0.1250\t 0.6250\t 0.1250\t\n",
      "\t2    |\t 0.1250\t 0.6250\t 0.1250\t 0.1250\t\n",
      "\t3    |\t 0.6250\t 0.1250\t 0.1250\t 0.1250\t\n",
      "\t4    |\t 0.1250\t 0.1250\t 0.6250\t 0.1250\t\n",
      "\t5    |\t 0.6250\t 0.1250\t 0.1250\t 0.1250\t\n",
      "\t6    |\t 0.1250\t 0.6250\t 0.1250\t 0.1250\t\n",
      "\t7    |\t 0.6250\t 0.1250\t 0.1250\t 0.1250\t\n",
      "\t8    |\t 0.1250\t 0.1250\t 0.1250\t 0.6250\t\n"
     ]
    }
   ],
   "source": [
    "# 打印文档/主题概率分布\n",
    "def print_topic(m):\n",
    "    print('topic of documents:');\n",
    "    print('Document\\\\topic\\t',end='')\n",
    "    for i in range(m.shape[0]):\n",
    "        print(' {} \\t'.format(i+1),end='');\n",
    "        pass;\n",
    "    print('',end='\\n');\n",
    "    print(' '*8*2,end='');\n",
    "    for i in range(m.shape[0]):\n",
    "        print('-'*8,end='');\n",
    "        pass;\n",
    "    print('',end='\\n');\n",
    "    for i in range(m.shape[1]):\n",
    "        print('\\t{}    |\\t'.format(i+1),end='')\n",
    "        for j in range(m.shape[0]):\n",
    "            if m[j,i] < 1e-4:\n",
    "                print(' 0\\t',end='')\n",
    "            else:\n",
    "                print(' {:.4f}\\t'.format(m[j,i]),end='');\n",
    "        print('',end='\\n');\n",
    "print_topic(theta.T);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words of topic:\n",
      "topic\\words\t 1 \t\t 2 \t\t 3 \t\t 4 \t\t 5 \t\t 6 \t\t\n",
      "\t1:\tbrushing\tmountain\tclimb\t\tair\t\tWhen\t\tSam\t\t\n",
      "\t2:\tmountain\t7up\t\tArt\t\tclimb\t\tair\t\tWhen\t\t\n",
      "\t3:\tair\t\tscary\t\tmountain\tclimb\t\tWhen\t\tSam\t\t\n",
      "\t4:\tfriends\t\tmountain\tclimb\t\tair\t\tWhen\t\tSam\t\t\n"
     ]
    }
   ],
   "source": [
    "# 打印单词/主题概率分布\n",
    "def print_words_of_topic(m,n_words,words):\n",
    "    print('words of topic:');\n",
    "    print('topic\\\\words\\t',end='')\n",
    "    for i in range(min(m.shape[0],n_words)):\n",
    "        print(' {} \\t\\t'.format(i+1),end='');\n",
    "        pass;\n",
    "    print('',end='\\n');\n",
    "    for i in range(m.shape[1]):\n",
    "        m_i = list(m[:,i]);\n",
    "        sorted_nums = sorted(enumerate(m_i), key=lambda x: x[1],reverse=True)\n",
    "        idx = [j[0] for j in sorted_nums]\n",
    "        nums = [j[1] for j in sorted_nums]\n",
    "        print('\\t{}:\\t'.format(i+1),end='')\n",
    "        for j in range(min(m.shape[0],n_words)):\n",
    "            word = words[idx[j]];\n",
    "            print(word,end='');\n",
    "            if len(word)<8:\n",
    "                print('\\t\\t',end='');\n",
    "            else:\n",
    "                print('\\t',end='');\n",
    "        print('',end='\\n');\n",
    "print_words_of_topic(m=phi.T,n_words=6,words=voc_list);\n",
    "# n_words: 最大单词显示数量\n",
    "# 该函数依概率打印前 n_words 个单词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d5d21e79f1d5ba1c56103bc8e531dbdd1e64dc8cd604e6393178b5ef12db8e16"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('tf_gpu': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
